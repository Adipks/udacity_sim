{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Make a Self-Driving Car\n",
    "\n",
    "Udacity recently open sourced their self driving car simulator\n",
    "originally built for SDND students\n",
    "\n",
    "![alt text](https://github.com/udacity/self-driving-car-sim/raw/master/sim_image.png \"Logo Title Text 1\")\n",
    "\n",
    "- built in Unity (free game making engine https://unity3d.com/)\n",
    "- add new tracks, change prebuilt scripts like gravity acceleration easily\n",
    "\n",
    "\n",
    "    \n",
    "## Data Generation \n",
    "\n",
    "- records images from center, left, and right cameras w/ associated steering angle, speed, throttle and brake. \n",
    "- saves to CSV\n",
    "- ideally you have a joystick, but keyboard works too\n",
    "\n",
    "\n",
    "## Training Mode - Behavioral cloning\n",
    "\n",
    "We use a 9 layer convolutional network, based off of Nvidia's\n",
    "end-to-end learning for self driving car paper. 72 hours of driving data was collected in all sorts of conditions from human drivers\n",
    "\n",
    "https://www.youtube.com/watch?v=NJU9ULQUwng\n",
    "\n",
    "#### Hardware design:\n",
    "\n",
    "![alt text](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/data-collection-system.png \"Logo Title Text 1\")\n",
    "\n",
    "- 3 cameras\n",
    "-  The steering command is obtained by tapping into the vehicleâ€™s Controller Area Network (CAN) bus.\n",
    "- Nvidia's Drive PX onboard computer with GPUs\n",
    "\n",
    "In order to make the system independent of the car geometry, the steering command is 1/r, where r is the turning radius in meters.  1/r was used instead of r to prevent a singularity when driving straight (the turning radius for driving straight is infinity). 1/r smoothly transitions through zero from left turns (negative values) to right turns (positive values).\n",
    "\n",
    "\n",
    "#### Software Design (supervised learning!) :\n",
    "\n",
    "![alt text](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/training.png \"Logo Title Text 1\")\n",
    "\n",
    "Images are fed into a CNN that then computes a proposed steering command. The proposed command is compared to the desired command for that image, and the weights of the CNN are adjusted to bring the CNN output closer to the desired output. The weight adjustment is accomplished using back propagation\n",
    "\n",
    "Eventually, it generated steering commands using just a single camera\n",
    "\n",
    "![alt text](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/inference.png \"Logo Title Text 1\")\n",
    "\n",
    "## Testing mode\n",
    "\n",
    "We will just run autonomous mode, then run our model and the car will start driving\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1440/1*nlusa_fC5BnsgnWPFnov7Q.tiff \"Logo Title Text 1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Install dependencies\n",
    "\n",
    "#TensorFlow without GPU\n",
    "conda env create -f environments.yml \n",
    "\n",
    "#Use TensorFlow with GPU\n",
    "conda env create -f environments-gpu.yml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to run send steering and throttle commands based on the prediction(note:certain packages may be outdated please configure the environment correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing command line arguments\n",
    "import argparse\n",
    "#decoding camera images\n",
    "import base64\n",
    "#for frametimestamp saving\n",
    "from datetime import datetime\n",
    "#reading and writing files\n",
    "import os\n",
    "#high level file operations\n",
    "import shutil\n",
    "#matrix math\n",
    "import numpy as np\n",
    "#real-time server\n",
    "import socketio\n",
    "#concurrent networking \n",
    "import eventlet\n",
    "#web server gateway interface\n",
    "import eventlet.wsgi\n",
    "#image manipulation\n",
    "from PIL import Image\n",
    "#web framework\n",
    "from flask import Flask\n",
    "#input output\n",
    "from io import BytesIO\n",
    "\n",
    "#load our saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "#helper class\n",
    "import utils\n",
    "\n",
    "#initialize our server\n",
    "sio = socketio.Server()\n",
    "#our flask (web) app\n",
    "app = Flask(__name__)\n",
    "#init our model and image array as empty\n",
    "model = None\n",
    "prev_image_array = None\n",
    "\n",
    "#set min/max speed for our autonomous car\n",
    "MAX_SPEED = 25\n",
    "MIN_SPEED = 10\n",
    "\n",
    "#and a speed limit\n",
    "speed_limit = MAX_SPEED\n",
    "\n",
    "#registering event handler for the server\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "    if data:\n",
    "        # The current steering angle of the car\n",
    "        steering_angle = float(data[\"steering_angle\"])\n",
    "        # The current throttle of the car, how hard to push peddle\n",
    "        throttle = float(data[\"throttle\"])\n",
    "        # The current speed of the car\n",
    "        speed = float(data[\"speed\"])\n",
    "        # The current image from the center camera of the car\n",
    "        image = Image.open(BytesIO(base64.b64decode(data[\"image\"])))\n",
    "        try:\n",
    "            image = np.asarray(image)       # from PIL image to numpy array\n",
    "            image = utils.preprocess(image) # apply the preprocessing\n",
    "            image = np.array([image])       # the model expects 4D array\n",
    "\n",
    "            # predict the steering angle for the image\n",
    "            steering_angle = float(model.predict(image, batch_size=1))\n",
    "            # lower the throttle as the speed increases\n",
    "            # if the speed is above the current speed limit, we are on a downhill.\n",
    "            # make sure we slow down first and then go back to the original max speed.\n",
    "            global speed_limit\n",
    "            if speed > speed_limit:\n",
    "                speed_limit = MIN_SPEED  # slow down\n",
    "            else:\n",
    "                speed_limit = MAX_SPEED\n",
    "            throttle = 1.0 - steering_angle**2 - (speed/speed_limit)**2\n",
    "\n",
    "            print('{} {} {}'.format(steering_angle, throttle, speed))\n",
    "            send_control(steering_angle, throttle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # save frame\n",
    "        if args.image_folder != '':\n",
    "            timestamp = datetime.utcnow().strftime('%Y_%m_%d_%H_%M_%S_%f')[:-3]\n",
    "            image_filename = os.path.join(args.image_folder, timestamp)\n",
    "            image.save('{}.jpg'.format(image_filename))\n",
    "    else:\n",
    "        \n",
    "        sio.emit('manual', data={}, skip_sid=True)\n",
    "\n",
    "\n",
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control(0, 0)\n",
    "\n",
    "\n",
    "def send_control(steering_angle, throttle):\n",
    "    sio.emit(\n",
    "        \"steer\",\n",
    "        data={\n",
    "            'steering_angle': steering_angle.__str__(),\n",
    "            'throttle': throttle.__str__()\n",
    "        },\n",
    "        skip_sid=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument(\n",
    "        'model',\n",
    "        type=str,\n",
    "        help='Path to model h5 file. Model should be on the same path.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'image_folder',\n",
    "        type=str,\n",
    "        nargs='?',\n",
    "        default='',\n",
    "        help='Path to image folder. This is where the images from the run will be saved.'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #load model\n",
    "    model = load_model(args.model)\n",
    "\n",
    "    if args.image_folder != '':\n",
    "        print(\"Creating image folder at {}\".format(args.image_folder))\n",
    "        if not os.path.exists(args.image_folder):\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        print(\"RECORDING THIS RUN ...\")\n",
    "    else:\n",
    "        print(\"NOT RECORDING THIS RUN ...\")\n",
    "\n",
    "    # wrap Flask application with engineio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to train the model(chenge the path to the training dataset accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data analysis toolkit - create, read, update, delete datasets\n",
    "import numpy as np #matrix math\n",
    "from sklearn.model_selection import train_test_split #to split out training and testing data \n",
    "#keras is a high level wrapper on top of tensorflow (machine learning library)\n",
    "#The Sequential container is a linear stack of layers\n",
    "from keras.models import Sequential\n",
    "#popular optimization strategy that uses gradient descent \n",
    "from keras.optimizers import Adam\n",
    "#to save our model periodically as checkpoints for loading later\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#what types of layers do we want our model to have?\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "#helper class to define input shape and generate training images given image paths & steering angles\n",
    "from utils import INPUT_SHAPE, batch_generator\n",
    "#for command line arguments\n",
    "import argparse\n",
    "#for reading files\n",
    "import os\n",
    "\n",
    "#for debugging, allows for reproducible (deterministic) results \n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    #we'll store the camera images as our input data\n",
    "    X = data_df[['center', 'left', 'right']].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df['steering'].values\n",
    "\n",
    "    #now we can split the data into a training (80), testing(20), and validation set\n",
    "    #thanks scikit learn\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args.test_size, random_state=0)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def build_model(args):\n",
    "    \"\"\"\n",
    "    NVIDIA model used\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "\n",
    "    # the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Conv2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(args.keep_prob))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, args, X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \"\"\"\n",
    "    #Saves the model after every epoch.\n",
    "    #quantity to monitor, verbosity i.e logging mode (0 or 1), \n",
    "    #if save_best_only is true the latest best model according to the quantity monitored will not be overwritten.\n",
    "    #mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is\n",
    "    # made based on either the maximization or the minimization of the monitored quantity. For val_acc, \n",
    "    #this should be max, for val_loss this should be min, etc. In auto mode, the direction is automatically\n",
    "    # inferred from the name of the monitored quantity.\n",
    "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=args.save_best_only,\n",
    "                                 mode='auto')\n",
    "\n",
    "    #calculate the difference between expected steering angle and actual steering angle\n",
    "    #square the difference\n",
    "    #add up all those differences for as many data points as we have\n",
    "    #divide by the number of them\n",
    "    #that value is our mean squared error! this is what we want to minimize via\n",
    "    #gradient descent\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=args.learning_rate))\n",
    "\n",
    "    #Fits the model on data generated batch-by-batch by a Python generator.\n",
    "\n",
    "    #The generator is run in parallel to the model, for efficiency. \n",
    "    #For instance, this allows you to do real-time data augmentation on images on CPU in \n",
    "    #parallel to training your model on GPU.\n",
    "    #so we reshape our data into their appropriate batches and train our model simulatenously\n",
    "    model.fit_generator(batch_generator(args.data_dir, X_train, y_train, args.batch_size, True),\n",
    "                        args.samples_per_epoch,\n",
    "                        args.nb_epoch,\n",
    "                        max_q_size=1,\n",
    "                        validation_data=batch_generator(args.data_dir, X_valid, y_valid, args.batch_size, False),\n",
    "                        nb_val_samples=len(X_valid),\n",
    "                        callbacks=[checkpoint],\n",
    "                        verbose=1)\n",
    "\n",
    "#for command line args\n",
    "def s2b(s):\n",
    "    \"\"\"\n",
    "    Converts a string to boolean value\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    return s == 'true' or s == 'yes' or s == 'y' or s == '1'\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load train/validation data set and train the model\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Behavioral Cloning Training Program')\n",
    "    parser.add_argument('-d', help='data directory',        dest='data_dir',          type=str,   default='data')\n",
    "    parser.add_argument('-t', help='test size fraction',    dest='test_size',         type=float, default=0.2)\n",
    "    parser.add_argument('-k', help='drop out probability',  dest='keep_prob',         type=float, default=0.5)\n",
    "    parser.add_argument('-n', help='number of epochs',      dest='nb_epoch',          type=int,   default=10)\n",
    "    parser.add_argument('-s', help='samples per epoch',     dest='samples_per_epoch', type=int,   default=20000)\n",
    "    parser.add_argument('-b', help='batch size',            dest='batch_size',        type=int,   default=40)\n",
    "    parser.add_argument('-o', help='save best models only', dest='save_best_only',    type=s2b,   default='true')\n",
    "    parser.add_argument('-l', help='learning rate',         dest='learning_rate',     type=float, default=1.0e-4)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    #print parameters\n",
    "    print('-' * 30)\n",
    "    print('Parameters')\n",
    "    print('-' * 30)\n",
    "    for key, value in vars(args).items():\n",
    "        print('{:<20} := {}'.format(key, value))\n",
    "    print('-' * 30)\n",
    "\n",
    "    #load data\n",
    "    data = load_data(args)\n",
    "    #build model\n",
    "    model = build_model(args)\n",
    "    #train model on data, it saves as model.h5 \n",
    "    train_model(model, args, *data)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Architecture Used\n",
    "\n",
    "The model is a Convolutional Neural Network (CNN) designed for processing images and predicting a single output value, such as a steering angle for autonomous driving applications. It is structured to handle feature extraction from images and make predictions using fully connected layers.\n",
    "\n",
    "## Architecture Details\n",
    "\n",
    "### Image Normalization:\n",
    "- **Layer**: Lambda\n",
    "- **Function**: Normalizes input images to the range [-1, 1]. This helps avoid saturation and ensures gradients work better during training.\n",
    "\n",
    "### Convolutional Layers:\n",
    "- **Purpose**: Extract features from the input images.\n",
    "\n",
    "  - **First Convolution**:\n",
    "    - **Filter Size**: 5x5\n",
    "    - **Number of Filters**: 24\n",
    "    - **Strides**: 2x2\n",
    "    - **Activation**: ELU (Exponential Linear Unit)\n",
    "\n",
    "  - **Second Convolution**:\n",
    "    - **Filter Size**: 5x5\n",
    "    - **Number of Filters**: 36\n",
    "    - **Strides**: 2x2\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Third Convolution**:\n",
    "    - **Filter Size**: 5x5\n",
    "    - **Number of Filters**: 48\n",
    "    - **Strides**: 2x2\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Fourth Convolution**:\n",
    "    - **Filter Size**: 3x3\n",
    "    - **Number of Filters**: 64\n",
    "    - **Strides**: 1x1\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Fifth Convolution**:\n",
    "    - **Filter Size**: 3x3\n",
    "    - **Number of Filters**: 64\n",
    "    - **Strides**: 1x1\n",
    "    - **Activation**: ELU\n",
    "\n",
    "- **Purpose**: To perform feature extraction using convolutional filters. ELU activation helps with the vanishing gradient problem by ensuring that gradients are always non-zero.\n",
    "\n",
    "### Dropout Layer:\n",
    "- **Layer**: Dropout\n",
    "- **Rate**: 0.5\n",
    "- **Purpose**: To reduce overfitting by randomly dropping units during training.\n",
    "\n",
    "### Fully Connected (Dense) Layers:\n",
    "- **Purpose**: To interpret features extracted by convolutional layers and make the final prediction.\n",
    "\n",
    "  - **First Dense**:\n",
    "    - **Neurons**: 100\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Second Dense**:\n",
    "    - **Neurons**: 50\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Third Dense**:\n",
    "    - **Neurons**: 10\n",
    "    - **Activation**: ELU\n",
    "\n",
    "  - **Output Dense**:\n",
    "    - **Neurons**: 1 (for prediction, e.g., steering angle)\n",
    "\n",
    "### Summary:\n",
    "- The CNN processes images through several convolutional layers for feature extraction.\n",
    "- Dropout is used to prevent overfitting.\n",
    "- Fully connected layers interpret the features and make a prediction based on the learned representations.\n",
    "\n",
    "### Key Points:\n",
    "- **Normalization**: Ensures inputs are within a suitable range for the network.\n",
    "- **Convolutional Layers**: Extract hierarchical features from images.\n",
    "- **Dropout**: Helps in generalization by preventing overfitting.\n",
    "- **ELU Activation**: Addresses the vanishing gradient problem and maintains gradient flow.\n",
    "\n",
    "This architecture is well-suited for tasks where feature extraction from images is crucial, followed by making predictions based on these features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "\n",
    "def load_image(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB images from a file\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "\n",
    "def crop(image):\n",
    "    \"\"\"\n",
    "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
    "    \"\"\"\n",
    "    return image[60:-25, :, :] # remove the sky and the car front\n",
    "\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"\n",
    "    Resize the image to the input shape used by the network model\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def rgb2yuv(image):\n",
    "    \"\"\"\n",
    "    Convert the image from RGB to YUV (This is what the NVIDIA model does)\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Combine all preprocess functions into one\n",
    "    \"\"\"\n",
    "    image = crop(image)\n",
    "    image = resize(image)\n",
    "    image = rgb2yuv(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def choose_image(data_dir, center, left, right, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly choose an image from the center, left or right, and adjust\n",
    "    the steering angle.\n",
    "    \"\"\"\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return load_image(data_dir, left), steering_angle + 0.2\n",
    "    elif choice == 1:\n",
    "        return load_image(data_dir, right), steering_angle - 0.2\n",
    "    return load_image(data_dir, center), steering_angle\n",
    "\n",
    "\n",
    "def random_flip(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly flipt the image left <-> right, and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def random_translate(image, steering_angle, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Randomly shift the image virtially and horizontally (translation).\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Generates and adds random shadow\n",
    "    \"\"\"\n",
    "    # (x1, y1) and (x2, y2) forms a line\n",
    "    # xm, ym gives all the locations of the image\n",
    "    x1, y1 = IMAGE_WIDTH * np.random.rand(), 0\n",
    "    x2, y2 = IMAGE_WIDTH * np.random.rand(), IMAGE_HEIGHT\n",
    "    xm, ym = np.mgrid[0:IMAGE_HEIGHT, 0:IMAGE_WIDTH]\n",
    "\n",
    "    # mathematically speaking, we want to set 1 below the line and zero otherwise\n",
    "    # Our coordinate is up side down.  So, the above the line: \n",
    "    # (ym-y1)/(xm-x1) > (y2-y1)/(x2-x1)\n",
    "    # as x2 == x1 causes zero-division problem, we'll write it in the below form:\n",
    "    # (ym-y1)*(x2-x1) - (y2-y1)*(xm-x1) > 0\n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "    # choose which side should have shadow and adjust saturation\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform(low=0.2, high=0.5)\n",
    "\n",
    "    # adjust Saturation in HLS(Hue, Light, Saturation)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond] * s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "\n",
    "def random_brightness(image):\n",
    "    \"\"\"\n",
    "    Randomly adjust brightness of the image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "\n",
    "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust steering angle.\n",
    "    (The steering angle is associated with the center image)\n",
    "    \"\"\"\n",
    "    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)\n",
    "    image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, steering_angle\n",
    "\n",
    "\n",
    "def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
    "    \"\"\"\n",
    "    Generate training image give image paths and associated steering angles\n",
    "    \"\"\"\n",
    "    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            # argumentation\n",
    "            if is_training and np.random.rand() < 0.6:\n",
    "                image, steering_angle = augument(data_dir, center, left, right, steering_angle)\n",
    "            else:\n",
    "                image = load_image(data_dir, center) \n",
    "            # add the image and steering angle to the batch\n",
    "            images[i] = preprocess(image)\n",
    "            steers[i] = steering_angle\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
